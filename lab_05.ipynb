{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "lab_05.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pietrzakkuba/computer-assisted-translation-labs/blob/main/lab_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "expanded-entrance"
      },
      "source": [
        "# Komputerowe wspomaganie tłumaczenia"
      ],
      "id": "expanded-entrance"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atlantic-greenhouse"
      },
      "source": [
        "# Zajęcia 5 - preprocessing i postprocessing"
      ],
      "id": "atlantic-greenhouse"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "colored-nothing"
      },
      "source": [
        "Na dzisiejszych zajęciach zajmiemy się niezwykle przydatnymi narzędziami wspomagającymi pracę tłumacza. W odróżnieniu od dotychczas poznanych, nie są one oparte na pamięci tłumaczeń, ani na słownikach. Chodzi o techniki preprocessingu i postprocessingu."
      ],
      "id": "colored-nothing"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atomic-rubber"
      },
      "source": [
        "Proces tłumaczenia przeprowadzony w pełni profesjonalnie składa się z wielu faz, które angażują nie tylko tłumaczy, ale także kierowników projektu, analityków, czy korektorów. Każda z tych osób do swojej pracy może wykorzystywać system informatyczny, do którego na początku całego procesu trafiają pliki do tłumaczenia. Oznacza to, że zanim tekst źródłowy trafi do tłumacza, system ma jeszcze szansę coś w nim zmienić. A kiedy tłumacz wykona już swoją pracę, można uruchomić kolejny mechanizm, który zmodyfikuje tłumaczenie przed oddaniem go do zamawiającego. Jak się domyślamy, modyfikacje tekstu przed przekazaniem go do tłumacza nazywamy **preprocessingiem**, natomiast te dokonywane po wykonaniu tłumaczenia (ale przed zwróceniem go do klienta) nazywamy **postprocessingiem**. Terminy te, będące mało zgrabnymi kalkami z języka angielskiego, mają wersje prawdziwie polskie: przetwarzanie wstępne i końcowe. Wersje te są jednak stosowane na tyle rzadko, że mogą jedynie wprowadzić zamieszanie (co w gruncie rzeczy jest dość smutne)."
      ],
      "id": "atomic-rubber"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mature-republic"
      },
      "source": [
        "Typowe operacje w fazie preprocessingu obejmują:\n",
        "* identyfikację tagów xmlowych (które często są później wyświetlane w interfejsie CAT-a jako jeden niepodzielny znak)\n",
        "* identyfikację segmentów, których nie należy tłumaczyć (na przykład składających się z samych liczb)\n",
        "\n",
        "* identyfikację dat i jednostek miary w tekście źródłowym\n",
        "\n",
        "We wszystkich tych operacjach niezwykle przydatne okazują się wyrażenia regularne."
      ],
      "id": "mature-republic"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "southern-applicant"
      },
      "source": [
        "### Ćwiczenie 1: Używając wyrażeń regularnych napisz funkcję do znajdowania wszystkich tagów XML w tekście. Funkcja powinna zwracać pozycje, na których znalazła tagi."
      ],
      "id": "southern-applicant"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "documented-hacker",
        "outputId": "64154be0-a96e-4f35-a117-55c497d6559d"
      },
      "source": [
        "import re\n",
        "\n",
        "def find_tags(text):\n",
        "    return [(tag.start(), tag.end()) for tag in list(re.finditer('(</?[0-9A-z]+>)', text))]\n",
        "\n",
        "find_tags('<title>Tytuł</title>')"
      ],
      "id": "documented-hacker",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 7), (12, 20)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "determined-utilization"
      },
      "source": [
        "### Ćwiczenie 2: Używając wyrażeń regularnych napisz funkcję do identyfikacji segmentów, których nie należy tłumaczyć. Zastosuj wymyślone przez siebie kryteria."
      ],
      "id": "determined-utilization"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unauthorized-study",
        "outputId": "3b11a36a-dea4-4725-c431-6f9a6ae55361"
      },
      "source": [
        "def is_translatable(text):\n",
        "    for pattern in ['^-?[0-9][0-9,\\.]+$', 'www.', 'https?://']:\n",
        "        if re.match(pattern, text) is not None:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "is_translatable('https://pl.wikipedia.org/wiki/Pa%C5%84stwa_uczestnicz%C4%85ce_w_Zimowych_Igrzyskach_Olimpijskich_1988')"
      ],
      "id": "unauthorized-study",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plastic-crown"
      },
      "source": [
        "### Ćwiczenie 3: Używając wyrażeń regularnych napisz funkcję do identyfikacji i interpretacji 5 wybranych przez siebie formatów daty. Funkcja powinna zwracać pozycje, na których odnalazła daty oraz dzień, miesiąc i rok, które ta data reprezentuje."
      ],
      "id": "plastic-crown"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beautiful-mathematics",
        "outputId": "3bd1cef5-47a0-4881-bb63-28a6b07246bb"
      },
      "source": [
        "def retrieve_data(match, format):\n",
        "    val = match.group()\n",
        "    pos_start = match.start()\n",
        "    pos_end = match.end()\n",
        "    if (format == 'rmd'): # te nazwy formatów moje własne\n",
        "        year = val[:4]\n",
        "        month = val[5:7]\n",
        "        day = val[8:]\n",
        "    elif (format == 'dmr'):\n",
        "        year = val[6:]\n",
        "        month = val[3:5]\n",
        "        day = val[:2]\n",
        "    elif (format == 'dmr-short'):\n",
        "        parts = val.split('/')\n",
        "        year = parts[2]\n",
        "        month = parts[1]\n",
        "        day = parts[0]\n",
        "    elif (format == 'american?'):\n",
        "        parts = val.split('/')\n",
        "        year = parts[2]\n",
        "        month = parts[0]\n",
        "        day = parts[1]\n",
        "    return {\n",
        "        'pos_start': pos_start,\n",
        "        'pos_end': pos_end,\n",
        "        'day': day,\n",
        "        'month': month,\n",
        "        'year': year\n",
        "    }\n",
        "\n",
        "\n",
        "def find_dates(text):\n",
        "    patterns = [\n",
        "        ('[0-9]{4}-(0[0-9]|1[1-2])-([0-2][0-9]|3[0-1])', 'rmd'),\n",
        "        ('[0-9]{4}/(0[0-9]|1[1-2])/([0-2][0-9]|3[0-1])', 'rmd'),\n",
        "        ('([0-2][0-9]|3[0-1])\\.(0[1-9]|1[1-2])\\.[0-9]{4}', 'dmr'),\n",
        "        ('([1-9]|[1-2][0-9]|3[0-1])/([0-9]|1[1-2])/[0-9]{4}', 'dmr-short'),\n",
        "        ('(0[1-9]|1[1-2])/([0-2][0-9]|3[0-1])/[0-9]{4}', 'american?')\n",
        "    ]\n",
        "    dates = []\n",
        "    for (pattern, format) in patterns:\n",
        "        matches = list(re.finditer(pattern, text))\n",
        "        for match in matches:\n",
        "            if match is not None:\n",
        "                dates.append(retrieve_data(match, format))\n",
        "    return dates\n",
        "\n",
        "find_dates('2021-04-07 2021/04/07 07.04.2021 7/4/2021 04/07/2021' )\n"
      ],
      "id": "beautiful-mathematics",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'day': '07', 'month': '04', 'pos_end': 10, 'pos_start': 0, 'year': '2021'},\n",
              " {'day': '07', 'month': '04', 'pos_end': 21, 'pos_start': 11, 'year': '2021'},\n",
              " {'day': '07', 'month': '04', 'pos_end': 32, 'pos_start': 22, 'year': '2021'},\n",
              " {'day': '7', 'month': '4', 'pos_end': 41, 'pos_start': 33, 'year': '2021'},\n",
              " {'day': '07', 'month': '04', 'pos_end': 52, 'pos_start': 42, 'year': '2021'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hourly-incentive"
      },
      "source": [
        "Po preprocessingu i tłumaczeniu czas na postprocessing. Ponieważ wykonywany jest on na przetłumaczonym tekście, jego głównym zadaniem jest eliminacja błędów popełnionych przez tłumacza w fazie tłumaczenia. Podczas postprocessingu najczęściej wykonuje się:\n",
        "* korektę pisowni dla języka docelowego\n",
        "* usuwanie błędów typograficznych z tekstu (np. wielokrotne spacje, brak spacji po przecinku)\n",
        "Stanowi to bardzo ważne wsparcie dla edytorów i korektorów, czyli osób sprawdzających pracę tłumacza.\n",
        "\n",
        "Jednak nowoczesne CAT-y potrafią coś jeszcze. Są w stanie w sprytny sposób wykorzystać kombinację pre- i postprocessingu do wyręczenia tłumacza w żmudnych i technicznych czynnościach. Wykonajmy następujące ćwiczenie:"
      ],
      "id": "hourly-incentive"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dental-combination"
      },
      "source": [
        "### Ćwiczenie 4: Wykorzystując funkcję find_dates napisz funkcję do obsługi dat w tłumaczeniu. Wejściem jest segment źródłowy oraz docelowy, które zawierają daty, przy czym daty te mogą być w różnych formatach. Dodatkowym parametrem wejściowym jest nazwa oczekiwanego formatu daty w tłumaczeniu (np. \"Europe\", \"US\", \"digit-dot\". Funkcja najpierw sprawdza, czy liczba dat w tłumaczeniu zgadza się z liczbą dat w segmencie źródłowym oraz czy odpowiadające sobie daty wskazują na ten sam dzień. Jeśli nie, wypisywane jest stosowne ostrzeżenie. Oczekiwanym wyjściem jest segment docelowy, w którym wszystkie daty są w żądanym formacie. "
      ],
      "id": "dental-combination"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "finished-essex",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e1a68a2-0659-44b7-dca1-d54b0358505c"
      },
      "source": [
        "def build_date(date, date_format):\n",
        "    if date_format == 'rrrr-mm-dd':\n",
        "        return date['year'] + '-' + str(date['month'])  + '-' + str(date['day'])\n",
        "    if date_format == 'dd.mm.yyyy':\n",
        "        return date['day'] + '.' + str(date['month'])  + '.' + str(date['year'])\n",
        "    if date_format == 'mm/dd/yyyy':\n",
        "        return date['month'] + '/' + str(date['day'])  + '/' + str(date['year'])\n",
        "\n",
        "def correct_dates(source_segment, target_segment, date_format):\n",
        "    dates_source = find_dates(source_segment)\n",
        "    dates_target = find_dates(target_segment)\n",
        "    if len(dates_source) != len(dates_target):\n",
        "        print(f'OSTRZEŻENIE: liczba dat w tłumaczeniu ({len(dates_target)}) nie zgadza się z liczbą dat w segmencie źródłowym ({len(dates_source)})')\n",
        "    for source_date, target_date in zip(dates_source, dates_target):\n",
        "        if source_date != target_date:\n",
        "            print(f'OSTRZEŻENIE: data z segemtnu źródłowego {source_date} nie zgadza się z datą w segmencie z tłumaczenia {target_date}')\n",
        "    if date_format != 'rrrr-mm-dd' and date_format != 'dd.mm.yyyy' and date_format != 'mm/dd/yyyy':\n",
        "        return 'BŁĄD: nieobsługiwany format daty'\n",
        "    for date in dates_target:\n",
        "        target_segment = target_segment[:date['pos_start']] + build_date(date, date_format) + target_segment[date['pos_end']:]\n",
        "    return target_segment\n",
        "\n",
        "\n",
        "correct_dates('2021-04-07 2021/04/07 07.04.2021 04/07/2021', '2021-04-07 2021/04/07 07.04.2021 04/07/2021', 'mm/dd/yyyy')"
      ],
      "id": "finished-essex",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'04/07/2021 04/07/2021 04/07/2021 04/07/2021'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vertical-divide"
      },
      "source": [
        "Co jeszcze można zrobić? Zajmijmy się tagami XML. Z punktu widzenia tłumacza najlepiej byłoby, gdyby mógł przetłumaczyć segment źródłowy zawierający tagi XML na język docelowy zupełnie ignorując te tagi. Ponieważ jednak tagi muszą jakoś znaleźć się w segmencie docelowym, przydałaby się jakaś \"magiczna różdżka\", która przeniosłaby wszystkie tagi ze źródła do tłumaczenia na mniej więcej dobre miejsca. Spełnijmy marzenie tłumacza!"
      ],
      "id": "vertical-divide"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trained-trouble"
      },
      "source": [
        "Rozważmy następujący algorytm: na wejściu mamy segment źródłowy zawierający tagi oraz segment docelowy bez tagów. Dokonujemy tokenizacji segmentu źródłowego tak, aby tagi były osobnymi tokenami. Następnie przeprowadźmy tokenizację segmentu docelowego. Gdy to jest gotowe, możemy zabrać się za przenoszenie (kopiowanie) tagów z segmentu źródłowego do docelowego."
      ],
      "id": "trained-trouble"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "damaged-simpson"
      },
      "source": [
        "![Transfer tagów](img/tagtransfer.png)"
      ],
      "id": "damaged-simpson"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "numerical-southeast"
      },
      "source": [
        "Gdzie w segmencie docelowym powinien trafić tag? Przede wszystkim pomiędzy tokeny - nie chcemy rozbijać słów tagami. Pytanie tylko, pomiędzy które tokeny? Jeśli sytuacja jest taka, jak powyżej, kiedy segment źródłowy i docelowy mają taką samą liczbę słów nie będących tagami, przenosimy tagi na odpowiadające pozycje w tłumaczeniu. Natomiast jeśli długość tłumaczenia jest inna niż źródła, należy obliczać te pozycje w sposób proporcjonalny - jeśli np. mamy tag w źródle na pozycji 3, a tłumaczenie jest dwa razy dłuższe niż źródło, tag powinien być przeniesiony do tłumaczenia na pozycję 6. W przypadku niecałkowitych wartości proporcji stosujemy zaokrąglenia."
      ],
      "id": "numerical-southeast"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "separated-socket"
      },
      "source": [
        "### Ćwiczenie 5: Zaimplementuj opisany algorytm transferu tagów."
      ],
      "id": "separated-socket"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "romance-judge",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7ed01fba-ffcd-4064-a6a3-bef0cf80fd15"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def transfer_tags(source_segment, target_segment):\n",
        "    tags_ranges = find_tags(source_segment)\n",
        "    tags_positions = []\n",
        "    for index, tag in enumerate(tags_ranges):\n",
        "        tags_positions.append(len(word_tokenize(source_segment[:tag[0]])) - index * 3) # - index * 3 -> ignorowanie poprzedzających tagów (każdy to 3 słowa w word_tokenize) \n",
        "    tags_with_positions = list(zip([source_segment[tag_range[0]:tag_range[1]] for tag_range in tags_ranges], tags_positions))\n",
        "    source_len = len(word_tokenize(source_segment)) - 3 * len(tags_with_positions)\n",
        "    target_words = word_tokenize(target_segment)\n",
        "    proportion = len(target_words) / source_len\n",
        "    for index, (tag, position) in enumerate(tags_with_positions):\n",
        "        target_words.insert(round(position * proportion) + index, tag)\n",
        "    return ' '.join(target_words)\n",
        "\n",
        "transfer_tags('<quote> I\\'m Pooh </quote> - said Pooh', 'Jestem Puchatek - rzekł Puchatek')"
      ],
      "id": "romance-judge",
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<quote> Jestem Puchatek </quote> - rzekł Puchatek'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    }
  ]
}